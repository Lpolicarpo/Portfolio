{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization techniques\n",
    "\n",
    "The goal of this notebook is to study the effect of applying different regularization techniques in a Polynomial Regression model. The idea is to increase the model complexity by increasing the degree of the polynomial and using Lasso, Ridge and Elastic Net methods to avoid overfitting.\n",
    "\n",
    "For this exercise we will use the California housing dataset (target = 'median_house_value').\n",
    "\n",
    "1- Uploading and cleaning data   \n",
    "2- Designing a simple data pipeline to create dummy variables, change degree of polynomial and normalize  \n",
    "3- Test the different regularization methods using GridSearch  \n",
    "4- Test a more complex model (Random Forest)  \n",
    "5- Conclusion  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.feature_selection import SelectKBest, chi2,f_classif, f_regression, mutual_info_classif\n",
    "from sklearn.metrics import precision_recall_curve,roc_curve\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Lasso,Ridge,ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "fetch_housing_data()\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      "longitude             20640 non-null float64\n",
      "latitude              20640 non-null float64\n",
      "housing_median_age    20640 non-null float64\n",
      "total_rooms           20640 non-null float64\n",
      "total_bedrooms        20433 non-null float64\n",
      "population            20640 non-null float64\n",
      "households            20640 non-null float64\n",
      "median_income         20640 non-null float64\n",
      "median_house_value    20640 non-null float64\n",
      "ocean_proximity       20640 non-null object\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the categories in the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'<1H OCEAN':'LESS_1H_OCEAN', 'INLAND':'INLAND', 'ISLAND':'ISLAND', 'NEAR BAY':'NEAR_BAY', 'NEAR OCEAN':'NEAR_OCEAN'}\n",
    "housing['ocean_proximity'] = housing['ocean_proximity'].map(lambda s: d[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 2 more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = housing[\"total_bedrooms\"].median()\n",
    "housing[\"total_bedrooms\"].fillna(median, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables based on the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(housing['ocean_proximity'])\n",
    "housing = housing.drop('ocean_proximity', axis=1)\n",
    "housing = housing.join(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 16 columns):\n",
      "longitude                   20640 non-null float64\n",
      "latitude                    20640 non-null float64\n",
      "housing_median_age          20640 non-null float64\n",
      "total_rooms                 20640 non-null float64\n",
      "total_bedrooms              20640 non-null float64\n",
      "population                  20640 non-null float64\n",
      "households                  20640 non-null float64\n",
      "median_income               20640 non-null float64\n",
      "median_house_value          20640 non-null float64\n",
      "rooms_per_household         20640 non-null float64\n",
      "population_per_household    20640 non-null float64\n",
      "INLAND                      20640 non-null uint8\n",
      "ISLAND                      20640 non-null uint8\n",
      "LESS_1H_OCEAN               20640 non-null uint8\n",
      "NEAR_BAY                    20640 non-null uint8\n",
      "NEAR_OCEAN                  20640 non-null uint8\n",
      "dtypes: float64(11), uint8(5)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Partition into train and test\n",
    "\n",
    "Use `train_test_split` from `sklearn.model_selection` to partition the dataset into 70% for training and 30% for testing.\n",
    "\n",
    "You can use the 70% for training set as both training and validation by using cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "target_col = 'median_house_value'\n",
    "\n",
    "\n",
    "X = housing.drop([target_col], axis = 1)\n",
    "y = housing[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4128 entries, 19121 to 18254\n",
      "Data columns (total 15 columns):\n",
      "longitude                   4128 non-null float64\n",
      "latitude                    4128 non-null float64\n",
      "housing_median_age          4128 non-null float64\n",
      "total_rooms                 4128 non-null float64\n",
      "total_bedrooms              4128 non-null float64\n",
      "population                  4128 non-null float64\n",
      "households                  4128 non-null float64\n",
      "median_income               4128 non-null float64\n",
      "rooms_per_household         4128 non-null float64\n",
      "population_per_household    4128 non-null float64\n",
      "INLAND                      4128 non-null uint8\n",
      "ISLAND                      4128 non-null uint8\n",
      "LESS_1H_OCEAN               4128 non-null uint8\n",
      "NEAR_BAY                    4128 non-null uint8\n",
      "NEAR_OCEAN                  4128 non-null uint8\n",
      "dtypes: float64(10), uint8(5)\n",
      "memory usage: 374.9 KB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Polynomial transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206404.1664244186"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PolynomialFeatures from sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=True)\n",
    "X_tr = poly_features.fit_transform(X_train)\n",
    "\n",
    "features = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 15\n",
      "Final number of features: 136\n"
     ]
    }
   ],
   "source": [
    "print(\"Original number of features: \"+str(len(features)))\n",
    "print(\"Final number of features: \"+str(X_tr.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Scaling features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, use `StandardScaler` from `sklearn.preprocessing` to normalize the training and testing data, using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tr_st = scaler.fit_transform(X_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing models\n",
    "\n",
    "Use this function to display your cross val scores, or you may use your own custom function.\n",
    "\n",
    "**Either way it is important to display your results as you train new models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Data Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pipeline for the polynomial transformer and standard scaler processes\n",
    "\n",
    "prep_pipeline = Pipeline([\n",
    "        ('polynomial_transformer', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "        ('scaler', StandardScaler()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Linear regression on original features (no transformations) --- benchmark\n",
    "\n",
    "Train a simple linear regression model using `cross_val_score` with no regularization or feature transformations. This model will serve as your benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Linear regression SciKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [-4.56142091e+09 -4.72836524e+09 -4.82082692e+09 -4.78076718e+09\n",
      " -4.81602773e+09]\n",
      "Mean: -4741481595.184526\n",
      "Standard Deviation: 95906258.0276629\n"
     ]
    }
   ],
   "source": [
    "X_train_mod1 =  scaler.fit_transform(X_train)\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "display_scores(cross_val_score(reg, X_train_mod1, y_train, cv=5, scoring = 'neg_mean_squared_error'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Linear regression  (on transformed features: polynomial transformation + scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do as in **2.1** but with the original and transformed features (136 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [-3.47620692e+29 -3.85891621e+09 -4.76765843e+24]\n",
      "Mean: -1.1587515324761284e+29\n",
      "Standard Deviation: 1.638688420327861e+29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_mod2 = prep_pipeline.fit_transform(X_train)\n",
    "\n",
    "display_scores(cross_val_score(reg, X_train_mod2, y_train, cv=3, scoring = 'neg_mean_squared_error'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the error on the cross-validation is too high it is because the model is over-fitting. Regularization is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Ridge regression\n",
    "\n",
    "Using the same transformed dataset from **2.2**, train another linear model but this time apply L2 regularization. Run the model through grid search to find the optimal regularization hyperparams. Print the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  51, 101, 151, 201, 251, 301, 351, 401, 451, 501, 551, 601,\n",
       "       651])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1,700,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preparation',\n",
       "                                        Pipeline(memory=None,\n",
       "                                                 steps=[('polynomial_transformer',\n",
       "                                                         PolynomialFeatures(degree=2,\n",
       "                                                                            include_bias=False,\n",
       "                                                                            interaction_only=False,\n",
       "                                                                            order='C')),\n",
       "                                                        ('scaler',\n",
       "                                                         StandardScaler(copy=True,\n",
       "                                                                        with_mean=True,\n",
       "                                                                        with_std=True))],\n",
       "                                                 verbose=False)),\n",
       "                                       ('Ridge_reg',\n",
       "                                        Ridge(alpha=1.0, copy_X=True,\n",
       "                                              fit_intercept=True, max_iter=None,\n",
       "                                              normalize=False,\n",
       "                                              random_state=None, solver='auto',\n",
       "                                              tol=0.001))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'Ridge_reg__alpha': array([400, 450, 500, 550, 600, 650])}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_root_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'Ridge_reg__alpha': np.arange(400,700,50)}]\n",
    "\n",
    "full_pipeline_predictor = Pipeline([\n",
    "        (\"preparation\", prep_pipeline),\n",
    "        (\"Ridge_reg\", Ridge())\n",
    "    ])\n",
    "\n",
    "ridge_grid_search = GridSearchCV(full_pipeline_predictor, param_grid, cv=5,\n",
    "                           scoring = 'neg_root_mean_squared_error', return_train_score=True)\n",
    "\n",
    "ridge_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ridge_reg__alpha': 450}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-71361.76121948808"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [ -64998.68408651  -65992.66374544  -66223.64387646  -65935.67384834\n",
      " -127585.52904961]\n",
      "Mean: -78147.23892127315\n",
      "Standard Deviation: 24722.690642746456\n"
     ]
    }
   ],
   "source": [
    "display_scores(cross_val_score(ridge_grid_search, X_train, y_train, cv=5, scoring = 'neg_root_mean_squared_error'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Lasso regression\n",
    "\n",
    "Now do the same as in **2.3** but with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preparation',\n",
       "                                        Pipeline(memory=None,\n",
       "                                                 steps=[('polynomial_transformer',\n",
       "                                                         PolynomialFeatures(degree=2,\n",
       "                                                                            include_bias=False,\n",
       "                                                                            interaction_only=False,\n",
       "                                                                            order='C')),\n",
       "                                                        ('scaler',\n",
       "                                                         StandardScaler(copy=True,\n",
       "                                                                        with_mean=True,\n",
       "                                                                        with_std=True))],\n",
       "                                                 verbose=False)),\n",
       "                                       ('Lasso_reg',\n",
       "                                        Lasso(alpha=1.0, copy_X=True,\n",
       "                                              fit...\n",
       "                                              normalize=False, positive=False,\n",
       "                                              precompute=False,\n",
       "                                              random_state=None,\n",
       "                                              selection='cyclic', tol=0.0001,\n",
       "                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'Lasso_reg__alpha': array([  1,  51, 101, 151, 201, 251, 301, 351, 401, 451, 501, 551, 601,\n",
       "       651])}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_root_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'Lasso_reg__alpha': np.arange(1,700,50)}]\n",
    "\n",
    "full_pipeline_predictor = Pipeline([\n",
    "        (\"preparation\", prep_pipeline),\n",
    "        (\"Lasso_reg\", Lasso())\n",
    "    ])\n",
    "\n",
    "lasso_grid_search = GridSearchCV(full_pipeline_predictor, param_grid, cv=5, \n",
    "                           scoring = 'neg_root_mean_squared_error', return_train_score=True)\n",
    "\n",
    "lasso_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lasso_reg__alpha': 651}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-70982.07183120243"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [  -68457.02039674   -66513.75860289   -66631.24645763   -64207.52886099\n",
      " -4548069.28216259]\n",
      "Mean: -962775.767296169\n",
      "Standard Deviation: 1792647.2647110103\n"
     ]
    }
   ],
   "source": [
    "display_scores(cross_val_score(lasso_grid_search, X_train, y_train, cv=5, scoring = 'neg_root_mean_squared_error'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Elastic Net regression\n",
    "\n",
    "Do the same as in **2.3** and **2.4**, but now with Elastic Net. However, the grid search should be over the parameters alpha and  L1 ratio. Use just 3 values for L1 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preparation',\n",
       "                                        Pipeline(memory=None,\n",
       "                                                 steps=[('polynomial_transformer',\n",
       "                                                         PolynomialFeatures(degree=2,\n",
       "                                                                            include_bias=False,\n",
       "                                                                            interaction_only=False,\n",
       "                                                                            order='C')),\n",
       "                                                        ('scaler',\n",
       "                                                         StandardScaler(copy=True,\n",
       "                                                                        with_mean=True,\n",
       "                                                                        with_std=True))],\n",
       "                                                 verbose=False)),\n",
       "                                       ('ElasticNet_reg',\n",
       "                                        ElasticNet(alpha=1.0, copy_...\n",
       "                                                   random_state=None,\n",
       "                                                   selection='cyclic',\n",
       "                                                   tol=0.0001,\n",
       "                                                   warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'ElasticNet_reg__l1_ratio': array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
       "       0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95])}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_root_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'ElasticNet_reg__l1_ratio': np.arange(0,1,0.05)}]\n",
    "\n",
    "full_pipeline_predictor = Pipeline([\n",
    "        (\"preparation\", prep_pipeline),\n",
    "        (\"ElasticNet_reg\", ElasticNet())\n",
    "    ])\n",
    "\n",
    "ENR_grid_search = GridSearchCV(full_pipeline_predictor, param_grid, cv=5, \n",
    "                           scoring = 'neg_root_mean_squared_error', return_train_score=True)\n",
    "\n",
    "ENR_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ElasticNet_reg__l1_ratio': 0.9500000000000001}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENR_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-78647.94449692321"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENR_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [ -69542.45442077  -69455.82910268  -70804.6225084   -70905.8785971\n",
      " -140238.2967045 ]\n",
      "Mean: -84189.4162666908\n",
      "Standard Deviation: 28031.033364251514\n"
     ]
    }
   ],
   "source": [
    "display_scores(cross_val_score(ENR_grid_search, X_train, y_train, cv=5, scoring = 'neg_root_mean_squared_error'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1  Expected Results\n",
    "\n",
    "Before you compute the final_rmse on the test data using your best model, pause and reflect:\n",
    "- Does your best model have high variance? \n",
    "- Why was your best performing model better than the others?\n",
    "- What is your expected rmse score on your test data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the four models tested the linear regression with no polynomial transformation performed better (benchmark model).The mean squared error and cross validation standard variation displayed the lowest values, 68.854 and 699 respectively. It is worth noting the very small variance obtained. This suggests that this particular model generalizes very well with a reasonable error ,even though it is a fairly simple one.\n",
    "\n",
    "The polynomial transformation added a lot more complexity to the models to the point that it overfitted given that no regularization was applied. Interestingly the regularization was not able to reduce the variability of the models to the extent it would surpass the performance of our simple benchmark model. Note that Ridge and Lasso regression displayed reasonable square mean error but the cross validation standard deviation. One factor that is important to take into consideration is the immense number of features acquired after the polynomial transformation (from 15 to 135 features), not only exceeded the complexity of the model but also caused converge issues on both Lasso and Elastic Net regression.\n",
    "\n",
    "The expected rmse score for the test data should be close to the value obtained for the cross validation score for the chosen model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluating your best model on TESTING data\n",
    "\n",
    "Of the models you created above, choose the best one to test on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68406.01279745529\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train_mod1 =  scaler.fit_transform(X_train)\n",
    "X_test_mod1 =  scaler.fit_transform(X_test)\n",
    "\n",
    "reg.fit(X_train_mod1, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test_mod1) \n",
    "\n",
    "final_mse = mean_squared_error(y_test, y_pred) # swap 'YOUR_PREDICTIONS' with the predictions values your model produces\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(final_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_pred) # swap 'YOUR_PREDICTIONS' with the prediction values your model produces\n",
    "plt.xlim([-200000,800000])\n",
    "plt.ylim([-200000,800000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Try a more advanced model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preparation',\n",
       "                                        Pipeline(memory=None,\n",
       "                                                 steps=[('polynomial_transformer',\n",
       "                                                         PolynomialFeatures(degree=2,\n",
       "                                                                            include_bias=False,\n",
       "                                                                            interaction_only=False,\n",
       "                                                                            order='C')),\n",
       "                                                        ('scaler',\n",
       "                                                         StandardScaler(copy=True,\n",
       "                                                                        with_mean=True,\n",
       "                                                                        with_std=True))],\n",
       "                                                 verbose=False)),\n",
       "                                       ('Random_forest_reg',\n",
       "                                        RandomForestRegressor(b...\n",
       "                                                              min_samples_split=2,\n",
       "                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                              n_estimators=100,\n",
       "                                                              n_jobs=None,\n",
       "                                                              oob_score=False,\n",
       "                                                              random_state=42,\n",
       "                                                              verbose=0,\n",
       "                                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'Random_forest_reg__max_depth': array([2, 4, 6, 8])}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_root_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "param_grid = [{'Random_forest_reg__max_depth': np.arange(2,10,2)}]\n",
    "\n",
    "full_pipeline_predictor = Pipeline([\n",
    "        (\"preparation\", prep_pipeline),\n",
    "        (\"Random_forest_reg\", RandomForestRegressor(random_state=42, n_estimators =100))\n",
    "    ])\n",
    "\n",
    "rfreg_grid_search = GridSearchCV(full_pipeline_predictor, param_grid, cv=5,\n",
    "                           scoring = 'neg_root_mean_squared_error', return_train_score=True)\n",
    "\n",
    "rfreg_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random_forest_reg__max_depth': 8}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-55563.15440257113"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [-53467.92382251 -55161.10448251 -55416.68197657 -56705.65705882\n",
      " -57064.40467244]\n",
      "Mean: -55563.15440257113\n",
      "Standard Deviation: 1275.31597541294\n",
      "2277.3952929973602\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "display_scores(cross_val_score(rfreg_grid_search, X_train, y_train, cv=5, scoring = 'neg_root_mean_squared_error'))\n",
    "print (time.time()- start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [-53467.14198101 -55164.44995252 -55419.37810121 -56698.33620197\n",
      " -57067.07188905]\n",
      "Mean: -55563.27562515088\n",
      "Standard Deviation: 1274.6223272018574\n",
      "198.57852911949158\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "x_train_mod2 = prep_pipeline.fit_transform(X_train)\n",
    "display_scores(cross_val_score(RandomForestRegressor(random_state=42, n_estimators =100,max_depth=  8 ), x_train_mod2, y_train, cv=5, scoring = 'neg_root_mean_squared_error'))\n",
    "\n",
    "print (time.time()- start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model algorithm consists of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree. Therefore due to the nature of this algorithm it's expected to perform better than linear models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
